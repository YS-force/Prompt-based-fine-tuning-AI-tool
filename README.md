# ğŸ“˜ **Prompt-Based Fine-Tuning AI Tool**
### **Structured Product Information Extraction Using LLMs**  
**Author:** *Yuvashree R*  
**Repository:** https://github.com/YS-force/Prompt-based-fine-tuning-AI-tool

---

# ğŸš€ **1. Project Overview**

This project demonstrates how to build a complete end-to-end AI application that extracts structured product information from raw HTML-like input.  
Instead of expensive OpenAI fine-tuning, this project uses **prompt-based fine-tuning (few-shot learning)** with the **Groq LLaMA-3.3-70B** model â€” which is fast, free, and effective.

The system takes HTML like:

```
<div class='product'><h2>iPad Air</h2> ... </div>
```

And returns:

```json
{
  "product": "iPad Air",
  "price": 1344,
  "category": "audio",
  "brand": "Apple"
}
```

This fulfills all assignment requirements:
âœ” dataset  
âœ” fine-tuning (prompt-based)  
âœ” JSON output  
âœ” full-stack application  
âœ” secure API handling  
âœ” Groq LLM inference  

---

# ğŸ¯ **2. Goals of the Project**

âœ” Understand dataset-driven model conditioning  
âœ” Build prompts that mimic fine-tuning  
âœ” Integrate LLM with a backend  
âœ” Build a frontend to interact with the model  
âœ” Produce accurate JSON output  
âœ” Deliver a full-stack AI tool  

---

# ğŸ§  **3. Model Used â€” Groq LLaMA-3.3-70B**

### Why Groq?

- Free to use  
- Extremely fast inference  
- Ideal for extraction tasks  
- No token billing  
- Simple SDK for Node.js  

### Why Prompt-Based Fine-Tuning?

Instead of paid fine-tuning, we used **example-based prompt conditioning**, also called:

- Few-shot learning  
- Pattern training  
- Instruction tuning  

The model learns the expected pattern from dataset examples.

---

# ğŸ”§ **4. System Architecture**

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚         FRONTEND           â”‚
                   â”‚        (React App)         â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  POST Request
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚         BACKEND            â”‚
                   â”‚     Node.js + Express      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚  API Call
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    Groq LLaMA 3.3 70B      â”‚
                   â”‚ Extracts product details   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    FRONTEND JSON Output    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ›  **5. Backend (Node.js + Express)**

The backend:

1. Accepts user input  
2. Adds dataset-style prompt examples  
3. Sends request to Groq LLM  
4. Receives structured JSON  
5. Returns it to the frontend  

Example flow:

```js
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

app.post("/api/extract", async (req, res) => {
  const { input } = req.body;

  const response = await groq.chat.completions.create({
    model: "llama-3.3-70b-versatile",
    messages: [
      { role: "system", content: "Extract product info in JSON." },
      { role: "user", content: input }
    ]
  });

  res.json(JSON.parse(response.choices[0].message.content));
});
```

---

# ğŸ’» **6. Frontend (React)**

Frontend responsibilities:

- Textbox for user input  
- Button to trigger AI extraction  
- Sends data to backend  
- Shows neatly formatted JSON output  
- Handles loading and errors  

User workflow:

1. Paste product HTML  
2. Click **Extract**  
3. View parsed JSON  

---

# ğŸ§ª **7. Dataset & Fine-Tuning Method**

Example entry:

```json
{
  "input": "<div class='product'><h2>iPad Air</h2>...</div>",
  "output": {
    "product": "iPad Air",
    "price": 1344,
    "category": "audio",
    "brand": "Apple"
  }
}
```

The model learns:

- How prices are parsed  
- How brand names are extracted  
- How to structure JSON  
- How to identify product attributes  

This is the essence of **prompt-based fine-tuning**.

---

# ğŸ“‚ **8. Folder Structure**

```
Prompt-based-fine-tuning-AI-tool/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ server.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env (ignored)
â”‚
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”‚
â”‚â”€â”€ dataset/
â”‚   â””â”€â”€ product_extraction_examples.json
â”‚
â””â”€â”€ README.md
```

---

# ğŸ” **9. Security Features**

You implemented:

âœ” `.env` to store API keys  
âœ” `.gitignore` to prevent leaks  
âœ” Cleaned git history after accidental key commits  
âœ” Backend-only key exposure (not frontend)  
âœ” Groq key stays secure server-side  

---

# ğŸŒ **10. Running the Project**

## Backend Setup
```sh
cd backend
npm install
```

Create `.env`:
```
GROQ_API_KEY=your_groq_key
```

Start backend:
```sh
node server.js
```
â¡ Runs at http://localhost:4000

---

## Frontend Setup
```sh
cd frontend
npm install
npm start
```
â¡ Runs at http://localhost:3000

---

# ğŸ§ª **11. Example Input & Output**

### Input:
```
<div class='product'><h2>iPad Air</h2>
<span class='price'>$1344</span>
<span class='category'>audio</span>
<span class='brand'>Apple</span></div>
```

### Output:
```json
{
  "product": "iPad Air",
  "price": 1344,
  "category": "audio",
  "brand": "Apple"
}
```
